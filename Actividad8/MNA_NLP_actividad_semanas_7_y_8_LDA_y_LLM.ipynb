{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVND8xY2OKY"
      },
      "source": [
        "# Procesamiento de Lenguaje Natural\n",
        "\n",
        "## Maestría en Inteligencia Artificial Aplicada  \n",
        "**Tecnológico de Monterrey**  \n",
        "**Prof. Luis Eduardo Falcón Morales**\n",
        "\n",
        "### Actividad en Equipos - Semanas 7 y 8: LDA y LLM\n",
        "\n",
        "**Objetivo General**  \n",
        "En esta actividad trabajarán en equipos para proponer ideas de cómo aplicar la Inteligencia Artificial en tareas diarias de trabajo o áreas de exploración y aprendizaje. Se recomienda incluir tópicos de procesamiento de lenguaje natural (PLN).\n",
        "\n",
        "**Resultado Esperado**  \n",
        "Al finalizar la actividad, deberán contar con al menos una idea de proyecto viable para implementar, contribuyendo a su crecimiento como especialistas en IA y PLN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimHVFOv23lm"
      },
      "source": [
        "* **Nombres y matrículas:**\n",
        "\n",
        "  *   Carlos Pano Hernandez - A01066264\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "\n",
        "* **Número de Equipo: 64**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gut.\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables from the specific .env file\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv('.env')\n",
        "\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if api_key is None:\n",
        "    raise ValueError(\"OPENAI_API_KEY environment variable is not set\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Prueba de la API de OpenAI\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Hola, como estas? (Responde en 1 palabra y en Aleman)\"\n",
        ")\n",
        "\n",
        "# Imprimir la respuesta como test\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uYgtCvvJSmq"
      },
      "source": [
        "#### Paso 1: Propuesta Individual  \n",
        "Cada integrante del equipo deberá proponer una idea de proyecto que incluya:\n",
        "\n",
        "- **Problemática**: Descripción clara del problema a resolver.  \n",
        "- **Datos involucrados**: Tipos y fuentes de datos necesarios.  \n",
        "- **Origen de datos**: De dónde provienen los datos.  \n",
        "- **Áreas/departamentos**: Organizaciones involucradas en el proceso.  \n",
        "- **Modelos de IA**: Tecnologías de inteligencia artificial sugeridas.  \n",
        "- **Entregable**: Producto final esperado.  \n",
        "- **Tecnologías**: Stack tecnológico requerido.  \n",
        "- **Estimaciones**: Tiempos y costos aproximados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# PROPUESTA DE CARLOS PANO - STORI RUNBOOK AI ASSISTANT\n",
        "# =============================================================================\n",
        "\n",
        "# Prompt 1: Análisis inicial del problema\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un consultor experto en IA y análisis de proyectos. \n",
        "\n",
        "CONTEXTO: Stori es una Fintech que se dedica a la creación de productos financieros (tarjetas de crédito, cuentas de ahorro con dinero creciente, préstamos, etc.). Tienen una organización en Github con repositorios privados que contienen todo el código de la empresa.\n",
        "\n",
        "PROBLEMA IDENTIFICADO: Cada repositorio tiene un runbook (documento de troubleshooting) que contiene documentación para dar soporte a ingenieros sin contexto sobre cómo resolver problemas específicos.\n",
        "\n",
        "OBJETIVO: Crear un sistema de IA que automatice el acceso y consulta de estos runbooks.\n",
        "\n",
        "TAREA: Analiza este problema y proporciona:\n",
        "1. Identificación clara de la problemática\n",
        "2. Tipos de datos involucrados\n",
        "3. Origen de los datos\n",
        "4. Áreas/departamentos implicados\n",
        "5. Modelos de IA sugeridos\n",
        "6. Entregable propuesto\n",
        "7. Tecnologías requeridas\n",
        "8. Estimación de tiempos y costos\n",
        "\n",
        "Responde de manera estructurada y detallada.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"=== ANÁLISIS INICIAL - CARLOS PANO ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# =============================================================================\n",
        "# ESPACIO PARA OTRAS PROPUESTAS DE EQUIPO\n",
        "# =============================================================================\n",
        "\n",
        "# PROPUESTA 2: [NOMBRE DEL INTEGRANTE]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Paso 2: Selección y Desarrollo  \n",
        "De entre las ideas propuestas, seleccionen una para desarrollar en equipo:\n",
        "\n",
        "**a) Selección del LLM**  \n",
        "- Elegir un modelo de gran tamaño (ChatGPT, Gemini, Llama, Claude, etc.).  \n",
        "- Especificar modelo y versión a utilizar.\n",
        "\n",
        "**b) Ingeniería de Instrucciones**  \n",
        "- Utilizar técnicas de *prompt engineering* con el LLM seleccionado.  \n",
        "- Obtener guías y propuestas de implementación.  \n",
        "- Generar un *business case* detallado.  \n",
        "- Realizar preguntas iterativas para enriquecer la información.\n",
        "\n",
        "### Nota Importante  \n",
        "El objetivo **NO** es implementar la solución, sino generar documentación base para propuestas futuras dentro de la organización o proyectos personales.\n",
        "\n",
        "### Entregable Final  \n",
        "Incluir conclusiones finales de la actividad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C3k5sLGhnO1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ANÁLISIS INICIAL Y SELECCIÓN DE LLM ===\n",
            "### 1. Identificación clara de la problemática\n",
            "Los ingenieros nuevos o aquellos que no están familiarizados con los repositorios enfrentan dificultades al intentar resolver problemas específicos sin el contexto adecuado. Los runbooks están presentes, pero su consulta manual puede ser ineficiente y consume tiempo valioso. La falta de un sistema intuitivo de búsqueda y recuperación de información puede resultar en tiempos de inactividad prolongados y en decisiones subóptimas al abordar incidentes.\n",
            "\n",
            "### 2. Tipos de datos involucrados\n",
            "- **Documentación técnica**: Incluye runbooks, guías de troubleshooting y FAQs en formato markdown o texto.\n",
            "- **Metadatos de los repositorios**: Información sobre el contexto del código (como commits, autores, y fechas).\n",
            "- **Consultas de usuarios**: Preguntas y problemas comunes planteados por los ingenieros.\n",
            "\n",
            "### 3. Origen de los datos\n",
            "- **Repositorios de Github**: Todos los runbooks están documentados dentro de los repositorios de la organización de Stori en GitHub.\n",
            "- **Bases de datos de incidentes**: Historial de problemas y respuestas dadas por otros ingenieros que pueden complementarse con los runbooks.\n",
            "\n",
            "### 4. Áreas/departamentos implicados\n",
            "- **Ingeniería de software**: Los principales usuarios de la solución, quienes necesitan la documentación para resolver problemas.\n",
            "- **Operaciones y soporte**: Responsables de escalar problemas y asegurar que se cumplan los tiempos de respuesta.\n",
            "- **IT y seguridad**: Para garantizar que la solución cumpla con las políticas de acceso y tratamiento de datos.\n",
            "\n",
            "### 5. Modelos de IA sugeridos\n",
            "Para el sistema de automatización, se sugiere usar un modelo de lenguaje grande (LLM) que pueda manejar un contexto amplio y proporcionar respuestas relevantes a consultas específicas.\n",
            "- **Modelo sugerido**: OpenAI GPT-4 (preferiblemente en la variante con capacidades mejoradas para la comprensión del texto técnico).\n",
            "- **Alternativa**: Fine-tuning de modelos como BERT o T5 en la documentación específica de Stori para adaptar la comprensión del lenguaje.\n",
            "\n",
            "### 6. Entregable propuesto\n",
            "Desarrollo de un **asistente virtual de soporte basado en IA** que:\n",
            "- Permita el acceso mediante consultas en lenguaje natural.\n",
            "- Proporcione respuestas extraídas de runbooks.\n",
            "- Ofrezca sugerencias para problemas comunes.\n",
            "- Incorpore un sistema de aprendizaje continuo mediante feedback de los usuarios.\n",
            "\n",
            "### 7. Tecnologías requeridas\n",
            "- **Infraestructura**: AWS, Azure o Google Cloud para alojar el modelo y los datos.\n",
            "- **Desarrollo**: Node.js o Python para la API que conecte la interfaz de usuario con el modelo de IA.\n",
            "- **Interfaz**: React o Vue.js para el frontend, con capacidades de búsqueda en lenguaje natural.\n",
            "- **Base de datos**: Elasticsearch o MongoDB para indexación y almacenamiento eficiente de runbooks y metadatos.\n",
            "\n",
            "### 8. Estimación de tiempos y costos\n",
            "- **Investigación y diseño**: 2 semanas (análisis de necesidades y definición de requisitos).\n",
            "- **Desarrollo del modelo LLM**: 4-6 semanas (entrenamiento y fine-tuning, incluyendo pruebas).\n",
            "- **Desarrollo de la API y frontend**: 3-4 semanas (creación de la interfaz de usuario y la comunicación con el modelo).\n",
            "- **Pruebas y despliegue**: 2 semanas (pruebas de aceptación con ingenieros y ajuste de la solución).\n",
            "\n",
            "**Costos estimados**:\n",
            "- Contratación de expertos en IA: $15,000 - $30,000 (dependiendo de la experiencia y la duración del proyecto).\n",
            "- Costos de infraestructura en la nube: $500 - $2,000 mensuales (dependiendo del uso).\n",
            "- Otros gastos (licencias, herramientas, etc.): $1,000.\n",
            "\n",
            "**Total estimado**: $17,500 - $35,000 y un tiempo total de 11 - 14 semanas para implementación y despliegue. \n",
            "\n",
            "Este enfoque estructurado permitirá a Stori centralizar y simplificar el soporte técnico, lo que mejorará la eficiencia operativa y aumentará la satisfacción del equipo de ingeniería.\n",
            "\n",
            "=== PROPUESTA TÉCNICA CON INGENIERÍA DE INSTRUCCIONES ===\n",
            "### Propuesta Técnica Completa para un Sistema de IA Potenciado por un LLM\n",
            "\n",
            "#### 1. SELECCIÓN Y JUSTIFICACIÓN DEL LLM\n",
            "\n",
            "**Modelo específico seleccionado:**\n",
            "- **GPT-4 (gpt-4-turbo)**\n",
            "\n",
            "**Justificación técnica de la elección:**\n",
            "- **Rendimiento:** GPT-4 ofrece una comprensión avanzada y producción de texto de alta calidad, adecuada para aplicaciones complejas.\n",
            "- **Costo:** `gpt-4-turbo` es más eficiente en términos de costo sin comprometer la capacidad de respuesta.\n",
            "- **Escalabilidad:** Puede manejar múltiples consultas simultáneamente, ideal para aplicaciones con alto volumen de tráfico.\n",
            "\n",
            "**Comparativa con otros modelos:**\n",
            "- **GPT-3.5:** Menor rendimiento en tareas complejas y en la generación de respuestas más elaboradas.\n",
            "- **BERT:** Excepcional en tareas de comprensión, pero no diseñado para generación de texto.\n",
            "- **Claude:** Competitivo, pero aún no ha demostrado el mismo nivel de versatilidad y soporte en entornos de producción.\n",
            "\n",
            "**Configuración óptima para el caso de uso:**\n",
            "- **Temperatura:** 0.3 (para respuestas más coherentes)\n",
            "- **Cantidad de tokens:** Configurable de 150 a 500 dependiendo de la complejidad de la consulta.\n",
            "- **Inclusión de contexto:** Incorporar información adicional para mejorar la precisión de las respuestas.\n",
            "\n",
            "---\n",
            "\n",
            "#### 2. ARQUITECTURA DEL SISTEMA\n",
            "\n",
            "**Componentes principales:**\n",
            "1. **Frontend:** Interfaz gráfica de usuario (Gradio)\n",
            "2. **Backend:** Servidor API (Flask/Django)\n",
            "3. **Modelo LLM:** GPT-4-turbo\n",
            "4. **Sistema de RAG:** Para optimizar el acceso a información relevante.\n",
            "5. **Base de datos vectorial:** Para almacenar embeddings.\n",
            "\n",
            "**Flujo de datos:**\n",
            "- El usuario realiza una consulta a través de la interfaz de Gradio.\n",
            "- El backend procesa la consulta, consultando la base de datos vectorial para obtener contexto relevante.\n",
            "- Se genera una consulta optimizada para el modelo LLM.\n",
            "- El LLM produce una respuesta que se envía nuevamente al frontend.\n",
            "\n",
            "**Integración con GitHub API:**\n",
            "- Utilizar el API de GitHub para extraer información de repositorios relevantes como parte del contexto.\n",
            "- `requests` para realizar solicitudes y manejar respuestas.\n",
            "\n",
            "**Sistema de RAG (Retrieval Augmented Generation):**\n",
            "- Implementar un modelo de recuperación que busque información en la base de datos vectorial utilizando embeddings generados a partir de documentos relevantes.\n",
            "\n",
            "---\n",
            "\n",
            "#### 3. ESPECIFICACIONES TÉCNICAS\n",
            "\n",
            "**Framework de embeddings:**\n",
            "- **Sentence Transformers:** Para generar representaciones de texto a partir de documentos.\n",
            "\n",
            "**Base de datos vectorial:**\n",
            "- **Pinecone o Weaviate:** Para almacenar y consultar embeddings de manera eficiente.\n",
            "\n",
            "**Interfaz de usuario (Gradio):**\n",
            "- Crear un UI sencillo que permita la entrada de texto y visualice respuestas generadas por el modelo LLM.\n",
            "\n",
            "**Prompt templates optimizados:**\n",
            "- Crear plantillas ajustables que incluyan variables como:\n",
            "  ```text\n",
            "  \"Por favor, responde a la pregunta: '{user_question}' usando la información del contexto: '{context}'.\"\n",
            "  ```\n",
            "\n",
            "---\n",
            "\n",
            "#### 4. PLAN DE IMPLEMENTACIÓN\n",
            "\n",
            "**Fases del proyecto:**\n",
            "1. **Análisis y diseño:** Recolección de requisitos y diseño de la arquitectura.\n",
            "2. **Desarrollo de componentes:** Implementación del backend, frontend y base de datos.\n",
            "3. **Integración:** Conexión entre componentes, incluyendo el LLM y la base de datos.\n",
            "4. **Pruebas:** Pruebas unitarias y de sistemas para validar el flujo.\n",
            "5. **Despliegue:** Implementación del sistema en un entorno de producción.\n",
            "\n",
            "**Cronograma detallado:**\n",
            "- Fase 1: 2 semanas\n",
            "- Fase 2: 4 semanas\n",
            "- Fase 3: 2 semanas\n",
            "- Fase 4: 2 semanas\n",
            "- Fase 5: 1 semana\n",
            "- **Duración total:** 11 semanas\n",
            "\n",
            "**Recursos necesarios:**\n",
            "- **Desarrollo:** 2 ingenieros de software, 1 especialista en data science.\n",
            "- **Infraestructura:** Servidores en la nube, espacio en base de datos.\n",
            "\n",
            "**Riesgos y mitigaciones:**\n",
            "- **Riesgo:** Retraso en la integración.\n",
            "  **Mitigación:** Planificación detallada.\n",
            "- **Riesgo:** Cambios en la API de GitHub.\n",
            "  **Mitigación:** Mantener un monitoreo activo y pruebas regulares.\n",
            "\n",
            "---\n",
            "\n",
            "#### 5. MÉTRICAS DE ÉXITO\n",
            "\n",
            "**KPIs del proyecto:**\n",
            "- **Tiempo de respuesta promedio:** Menor a 2 segundos.\n",
            "- **Tasa de satisfacción del usuario:** Mayores al 85%.\n",
            "- **Precisión de las respuestas:** Evaluar mediante un conjunto de datos de validación.\n",
            "\n",
            "**Criterios de evaluación:**\n",
            "- Realizar evaluaciones intermedias durante las pruebas de integración.\n",
            "- Encuestas de satisfacción del usuario tras el despliegue inicial.\n",
            "- Análisis de logs para identificar puntos de mejora en el sistema.\n",
            "\n",
            "---\n",
            "\n",
            "Esta propuesta técnica ofrece un enfoque integral, destacando cómo la ingeniería de instrucciones optimiza cada etapa del flujo de procesamiento de solicitudes en un sistema basado en IA.\n",
            "\n",
            "=== ANÁLISIS DE VIABILIDAD Y BUSINESS CASE ===\n",
            "# Business Case para Proyecto de IA\n",
            "\n",
            "## 1. ANÁLISIS DE VIABILIDAD\n",
            "\n",
            "### Beneficios Cuantificables\n",
            "- **Incremento de ingresos**: Se proyecta un aumento del 15% en los ingresos anuales gracias a la automatización y personalización del servicio al cliente.\n",
            "- **Reducción de costos operativos**: Ahorros de hasta $200,000 anuales al reemplazar tareas manuales por automatización.\n",
            "\n",
            "### Ahorro de Tiempo Estimado\n",
            "- **Tareas administrativas**: Se estima que la implementación de IA puede reducir el tiempo en la gestión administrativa en un 40%, liberando aproximadamente 20 horas semanales por empleado.\n",
            "  \n",
            "### Mejora en la Productividad\n",
            "- **Velocidad de respuesta**: Disminución del tiempo de respuesta al cliente a menos de 1 minuto, aumentando la satisfacción del cliente.\n",
            "- **Capacitación del personal**: Procedimientos más eficientes reducirán el tiempo de entrenamiento en un 30%.\n",
            "\n",
            "### Reducción de Errores\n",
            "- **Errores humanos**: Se proyecta una reducción del 50% en errores derivados de procesos manuales al implementar sistemas de IA para verificación y validación.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. ANÁLISIS DE COSTOS\n",
            "\n",
            "### Costos de Desarrollo\n",
            "- **Desarrollo del Software**: $150,000 en personal y herramientas.\n",
            "- **Integración de Sistema**: $50,000 (consultores y especialistas).\n",
            "\n",
            "### Costos Operativos Mensuales\n",
            "- **Soporte técnico**: $3,000\n",
            "- **Mantenimiento del software**: $1,500\n",
            "- **Licencias**: $1,000\n",
            "\n",
            "### Costos de Infraestructura\n",
            "- **Servidores y almacenamiento en la nube**: $2,000 mensuales.\n",
            "- **Red de seguridad**: $1,000 mensuales.\n",
            "\n",
            "### ROI Estimado\n",
            "- **Costo total inicial**: $200,000\n",
            "- **Beneficios anuales**: $400,000\n",
            "- **ROI estimado**: 100% en 1 año.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. ANÁLISIS DE RIESGOS\n",
            "\n",
            "### Riesgos Técnicos\n",
            "- **Fallas en el sistema**: Riesgo de fallos en la automatización.\n",
            "  - **Plan de mitigación**: Pruebas exhaustivas antes de la implementación.\n",
            "\n",
            "### Riesgos de Negocio\n",
            "- **Adopción del usuario**: Resistencia al cambio por parte de los empleados.\n",
            "  - **Plan de mitigación**: Programa de capacitación y desarrollo de habilidades.\n",
            "\n",
            "### Riesgos de Seguridad\n",
            "- **Filtración de datos**: Posible comprometimiento de datos sensibles.\n",
            "  - **Plan de mitigación**: Establecimiento de protocolos de seguridad y auditorías regulares.\n",
            "\n",
            "---\n",
            "\n",
            "## 4. COMPARATIVA CON ALTERNATIVAS\n",
            "\n",
            "### Soluciones Existentes en el Mercado\n",
            "- ***Competencia directa***: Otras herramientas de CRM con capacidades de IA, como Salesforce y HubSpot.\n",
            "- ***Alternativas***: Herramientas internas de desarrollo de IA.\n",
            "\n",
            "### Ventajas Competitivas\n",
            "- **Personalización**: Solución adaptada específicamente a las necesidades de la empresa.\n",
            "- **Integración completa**: Sinergias con sistemas existentes que no ofrecen las soluciones estándar.\n",
            "\n",
            "### Diferenciadores\n",
            "- **Propiedad intelectual**: Desarrollo de algoritmos únicos basados en datos internos.\n",
            "- **Agilidad**: Capacidad de respuesta rápida a las necesidades del mercado.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. BUSINESS CASE\n",
            "\n",
            "### Propuesta Ejecutiva\n",
            "Implementar un sistema de IA que automatice tareas administrativas y mejore la interacción con el cliente. La IA permitirá incrementar la eficiencia operativa y reducir costos.\n",
            "\n",
            "### Justificación de Inversión\n",
            "La inversión inicial de $200,000 se recuperará en menos de un año a través de un aumento en ingresos y una considerable reducción en costos operativos, además de mejoramiento en la satisfacción del cliente.\n",
            "\n",
            "### Timeline de Implementación\n",
            "- **Fase 1**: Investigación y Desarrollo – 3 meses\n",
            "- **Fase 2**: Pruebas pilotos – 2 meses\n",
            "- **Fase 3**: Implementación total – 3 meses\n",
            "- **Total**: 8 meses para la operación total.\n",
            "\n",
            "### Métricas de Éxito\n",
            "- **Incremento en la satisfacción del cliente**: Medido a través de encuestas.\n",
            "- **Reducción en costos operativos**: Seguimiento mensual.\n",
            "- **Adopción de la solución**: Tasa de uso del sistema por parte de los empleados.\n",
            "\n",
            "---\n",
            "\n",
            "Este análisis integral proporciona una visión clara sobre la viabilidad y la justificación de la inversión en un proyecto de IA, así como los pasos necesarios para su implementación exitosa.\n",
            "\n",
            "=== README.md GENERADO ===\n",
            "```markdown\n",
            "# Stori Runbook AI Assistant\n",
            "\n",
            "![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)\n",
            "![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)\n",
            "![License](https://img.shields.io/badge/license-MIT-yellow.svg)\n",
            "\n",
            "## Tabla de Contenidos\n",
            "\n",
            "1. [Problemática](#problemática)\n",
            "2. [Solución Propuesta](#solución-propuesta)\n",
            "3. [Tecnologías Utilizadas](#tecnologías-utilizadas)\n",
            "4. [Instalación y Configuración](#instalación-y-configuración)\n",
            "5. [Uso](#uso)\n",
            "6. [Arquitectura](#arquitectura)\n",
            "7. [API Reference](#api-reference)\n",
            "8. [Proceso de Desarrollo](#proceso-de-desarrollo)\n",
            "9. [Contribución](#contribución)\n",
            "10. [Licencia](#licencia)\n",
            "11. [Contacto](#contacto)\n",
            "\n",
            "## Problemática\n",
            "\n",
            "En entornos de operaciones, el manejo ineficiente de procedimientos y documentación puede llevar a errores que impactan significativamente la productividad. Los runbooks tradicionales son difíciles de actualizar y mantener, lo que a menudo resulta en información obsoleta.\n",
            "\n",
            "### Impacto en la organización\n",
            "\n",
            "La falta de un sistema eficiente para acceder y manejar los runbooks puede llevar a malentendidos, errores en la ejecución de tareas y tiempos de respuesta prolongados en situaciones críticas.\n",
            "\n",
            "### Justificación del proyecto\n",
            "\n",
            "Desarrollar \"Stori Runbook AI Assistant\" proporciona una solución que garantiza que las operaciones cuenten con información precisa y accesible en todo momento, optimizando la eficiencia del equipo y mejorando la satisfacción del cliente.\n",
            "\n",
            "## Solución Propuesta\n",
            "\n",
            "### Arquitectura General\n",
            "\n",
            "El \"Stori Runbook AI Assistant\" está basado en una arquitectura de microservicios que permite escalabilidad y mantenibilidad.\n",
            "\n",
            "### Componentes Principales\n",
            "\n",
            "- **Frontend**: Interfaz de usuario intuitiva para la interacción con el asistente.\n",
            "- **Backend**: Servicios API que manejan la lógica del negocio.\n",
            "- **LLM**: Modelo de Lenguaje de Aprendizaje Profundo que facilita las consultas en lenguaje natural.\n",
            "\n",
            "### Flujo de Trabajo\n",
            "\n",
            "1. Usuario hace una consulta usando un lenguaje natural.\n",
            "2. El asistente convierte la consulta en un formato que el sistema puede procesar.\n",
            "3. El LLM proporciona la información necesaria.\n",
            "4. Los resultados se presentan al usuario en un formato comprensible.\n",
            "\n",
            "### LLM Seleccionado y Justificación\n",
            "\n",
            "Se ha seleccionado **GPT-4** debido a su capacidad avanzada para comprender y generar lenguaje natural, lo que permite una interacción fluida y precisa, optimizando así la experiencia del usuario.\n",
            "\n",
            "## Tecnologías Utilizadas\n",
            "\n",
            "- **Frontend**: React (v17.0.2)\n",
            "- **Backend**: Node.js (v14.18.1), Express (v4.17.1)\n",
            "- **Base de Datos**: MongoDB (v4.4.6)\n",
            "- **Modelo LLM**: OpenAI GPT-4\n",
            "- **Containerización**: Docker (v20.10.7)\n",
            "\n",
            "### Justificación de Elecciones\n",
            "\n",
            "- **React** para crear una interfaz de usuario dinámica y responsive.\n",
            "- **Node.js** y **Express** por su rendimiento y capacidad asíncrona.\n",
            "- **MongoDB** por su adaptabilidad a los requisitos no estructurados de los runbooks.\n",
            "\n",
            "## Instalación y Configuración\n",
            "\n",
            "### Prerrequisitos\n",
            "\n",
            "- Node.js (v14.18.1)\n",
            "- MongoDB (v4.4.6)\n",
            "- Docker (opcional para la containerización)\n",
            "\n",
            "### Pasos de Instalación\n",
            "\n",
            "1. Clonar el repositorio:\n",
            "   ```bash\n",
            "   git clone https://github.com/usuario/stori-runbook-ai-assistant.git\n",
            "   cd stori-runbook-ai-assistant\n",
            "   ```\n",
            "\n",
            "2. Instalar dependencias:\n",
            "   ```bash\n",
            "   npm install\n",
            "   ```\n",
            "\n",
            "3. Levantar la base de datos de MongoDB (si no se usa Docker):\n",
            "   ```bash\n",
            "   mongod\n",
            "   ```\n",
            "\n",
            "### Configuración de Variables de Entorno\n",
            "\n",
            "Crear un archivo `.env` y agregar las siguientes variables:\n",
            "```\n",
            "MONGO_URI=mongodb://localhost:27017/stori\n",
            "API_KEY=tu_api_key_aquí\n",
            "```\n",
            "\n",
            "## Uso\n",
            "\n",
            "### Instrucciones de Uso\n",
            "\n",
            "Una vez configurado, se puede levantar el servidor:\n",
            "```bash\n",
            "npm start\n",
            "```\n",
            "Acceder a la aplicación en `http://localhost:3000`.\n",
            "\n",
            "### Ejemplos Prácticos\n",
            "\n",
            "- **Consulta a un procedure**: \"¿Cómo reiniciar el servidor?\"\n",
            "- **Consultar logs**: \"Muestra los logs del último reinicio.\"\n",
            "\n",
            "### Capturas de Pantalla\n",
            "\n",
            "![Ejemplo de Interfaz](https://via.placeholder.com/800x400.png?text=Ejemplo+de+Interfaz)\n",
            "\n",
            "## Arquitectura\n",
            "\n",
            "### Diagrama de Componentes\n",
            "\n",
            "![Diagrama de Arquitectura](https://via.placeholder.com/800x400.png?text=Diagrama+de+Componentes)\n",
            "\n",
            "### Flujo de Datos\n",
            "\n",
            "1. El usuario introduce una consulta en el frontend.\n",
            "2. El frontend comunica la consulta al backend.\n",
            "3. El backend se comunica con el LLM para obtener una respuesta.\n",
            "4. La respuesta se devuelve al usuario.\n",
            "\n",
            "### Integraciones\n",
            "\n",
            "- **MongoDB** para el almacenamiento de runbooks.\n",
            "- **API de OpenAI** para el LLM.\n",
            "\n",
            "## API Reference\n",
            "\n",
            "### Endpoints Principales\n",
            "\n",
            "- **POST** `/api/query`\n",
            "  - **Parámetros**:\n",
            "    - `query`: string - La consulta del usuario.\n",
            "  - **Respuesta**:\n",
            "    - `response`: string - Respuesta generada por el LLM.\n",
            "\n",
            "## Proceso de Desarrollo\n",
            "\n",
            "### Metodología Utilizada\n",
            "\n",
            "Se siguió una metodología Agile, permitiendo iteraciones rápidas y flexibilidad de cambios.\n",
            "\n",
            "### Ingeniería de Instrucciones Aplicada\n",
            "\n",
            "El equipo utilizó técnicas de ingeniería de instrucciones para optimizar la precisión del LLM.\n",
            "\n",
            "### Iteraciones del Equipo\n",
            "\n",
            "El desarrollo se organizó en sprints de dos semanas, con revisiones y demostraciones regulares.\n",
            "\n",
            "## Contribución\n",
            "\n",
            "### Guías Para Contribuir\n",
            "\n",
            "1. Haz un fork del repositorio.\n",
            "2. Crea una nueva rama para tu feature.\n",
            "3. Realiza tu cambio y haz un Pull Request.\n",
            "\n",
            "### Estándares de Código\n",
            "\n",
            "- Estilo de código consistente con [Airbnb JavaScript Style Guide](https://github.com/airbnb/javascript).\n",
            "\n",
            "## Licencia\n",
            "\n",
            "MIT License. Ver el archivo [LICENSE](LICENSE) para más detalles.\n",
            "\n",
            "## Contacto\n",
            "\n",
            "- **Equipo de Desarrollo**: \n",
            "  - Juan Pérez - Desarrollador Backend\n",
            "  - Ana López - Desarrolladora Frontend\n",
            "  - Carlos García - Ingeniero de IA\n",
            "\n",
            "Para contactarnos, envía un correo a `equipo@stori.com`.\n",
            "```\n",
            "\n",
            "Este README.md está estructurado de manera profesional, cubriendo todos los aspectos necesarios y siguiendo buenas prácticas de documentación técnica.\n",
            "\n",
            "=== README.md EXPORTADO ===\n",
            "El archivo README.md ha sido guardado en el directorio actual.\n"
          ]
        }
      ],
      "source": [
        "# Prompt 1: Análisis inicial del problema y selección del LLM\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un consultor experto en IA y análisis de proyectos. \n",
        "\n",
        "CONTEXTO: Stori es una Fintech que se dedica a la creación de productos financieros (tarjetas de crédito, cuentas de ahorro con dinero creciente, préstamos, etc.). Tienen una organización en Github con repositorios privados que contienen todo el código de la empresa.\n",
        "\n",
        "PROBLEMA IDENTIFICADO: Cada repositorio tiene un runbook (documento de troubleshooting) que contiene documentación para dar soporte a ingenieros sin contexto sobre cómo resolver problemas específicos.\n",
        "\n",
        "OBJETIVO: Crear un sistema de IA que automatice el acceso y consulta de estos runbooks.\n",
        "\n",
        "TAREA: Analiza este problema y proporciona:\n",
        "1. Identificación clara de la problemática\n",
        "2. Tipos de datos involucrados\n",
        "3. Origen de los datos\n",
        "4. Áreas/departamentos implicados\n",
        "5. Modelos de IA sugeridos (especificar modelo LLM y versión preferida)\n",
        "6. Entregable propuesto\n",
        "7. Tecnologías requeridas\n",
        "8. Estimación de tiempos y costos\n",
        "\n",
        "Responde de manera estructurada y detallada.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"=== ANÁLISIS INICIAL Y SELECCIÓN DE LLM ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Prompt 2: Ingeniería de instrucciones y propuesta técnica detallada\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Basándote en el análisis anterior, ahora actúa como un arquitecto de soluciones de IA especializado en prompt engineering.\n",
        "\n",
        "TAREA: Utiliza técnicas de ingeniería de instrucciones para diseñar un pipeline técnico detallado que incluya:\n",
        "\n",
        "1. SELECCIÓN Y JUSTIFICACIÓN DEL LLM:\n",
        "   - Modelo específico seleccionado (versión exacta)\n",
        "   - Justificación técnica de la elección\n",
        "   - Comparativa con otros modelos\n",
        "   - Configuración óptima para el caso de uso\n",
        "\n",
        "2. ARQUITECTURA DEL SISTEMA:\n",
        "   - Componentes principales\n",
        "   - Flujo de datos\n",
        "   - Integración con GitHub API\n",
        "   - Sistema de RAG (Retrieval Augmented Generation)\n",
        "\n",
        "3. ESPECIFICACIONES TÉCNICAS:\n",
        "   - Framework de embeddings\n",
        "   - Base de datos vectorial\n",
        "   - Interfaz de usuario (Gradio)\n",
        "   - Prompt templates optimizados\n",
        "\n",
        "4. PLAN DE IMPLEMENTACIÓN:\n",
        "   - Fases del proyecto\n",
        "   - Cronograma detallado\n",
        "   - Recursos necesarios\n",
        "   - Riesgos y mitigaciones\n",
        "\n",
        "5. MÉTRICAS DE ÉXITO:\n",
        "   - KPIs del proyecto\n",
        "   - Criterios de evaluación\n",
        "\n",
        "Proporciona una propuesta técnica completa y ejecutable con énfasis en la ingeniería de instrucciones.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== PROPUESTA TÉCNICA CON INGENIERÍA DE INSTRUCCIONES ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Prompt 3: Análisis de viabilidad y business case\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un analista de negocio especializado en proyectos de IA.\n",
        "\n",
        "TAREA: Evalúa la viabilidad del proyecto desde la perspectiva de negocio y genera un business case detallado:\n",
        "\n",
        "1. ANÁLISIS DE VIABILIDAD:\n",
        "   - Beneficios cuantificables\n",
        "   - Ahorro de tiempo estimado\n",
        "   - Mejora en la productividad\n",
        "   - Reducción de errores\n",
        "\n",
        "2. ANÁLISIS DE COSTOS:\n",
        "   - Costos de desarrollo\n",
        "   - Costos operativos mensuales\n",
        "   - Costos de infraestructura\n",
        "   - ROI estimado\n",
        "\n",
        "3. ANÁLISIS DE RIESGOS:\n",
        "   - Riesgos técnicos\n",
        "   - Riesgos de negocio\n",
        "   - Riesgos de seguridad\n",
        "   - Planes de mitigación\n",
        "\n",
        "4. COMPARATIVA CON ALTERNATIVAS:\n",
        "   - Soluciones existentes en el mercado\n",
        "   - Ventajas competitivas\n",
        "   - Diferenciadores\n",
        "\n",
        "5. BUSINESS CASE:\n",
        "   - Propuesta ejecutiva\n",
        "   - Justificación de inversión\n",
        "   - Timeline de implementación\n",
        "   - Métricas de éxito\n",
        "\n",
        "Proporciona un análisis completo de viabilidad empresarial y business case ejecutivo.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== ANÁLISIS DE VIABILIDAD Y BUSINESS CASE ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Prompt 4: Generación del README.md con información del equipo y proceso\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un documentador técnico experto.\n",
        "\n",
        "TAREA: Genera un README.md completo y profesional para el proyecto \"Stori Runbook AI Assistant\" que incluya:\n",
        "\n",
        "1. TÍTULO Y DESCRIPCIÓN:\n",
        "   - Nombre del proyecto\n",
        "   - Descripción clara y concisa\n",
        "   - Badges relevantes\n",
        "\n",
        "2. TABLA DE CONTENIDOS:\n",
        "   - Navegación clara\n",
        "\n",
        "3. PROBLEMÁTICA:\n",
        "   - Descripción del problema\n",
        "   - Impacto en la organización\n",
        "   - Justificación del proyecto\n",
        "\n",
        "4. SOLUCIÓN PROPUESTA:\n",
        "   - Arquitectura general\n",
        "   - Componentes principales\n",
        "   - Flujo de trabajo\n",
        "   - LLM seleccionado y justificación\n",
        "\n",
        "5. TECNOLOGÍAS UTILIZADAS:\n",
        "   - Stack tecnológico completo\n",
        "   - Versiones específicas\n",
        "   - Justificación de elecciones\n",
        "   - Modelo LLM específico (versión)\n",
        "\n",
        "6. INSTALACIÓN Y CONFIGURACIÓN:\n",
        "   - Prerrequisitos\n",
        "   - Pasos de instalación\n",
        "   - Configuración de variables de entorno\n",
        "\n",
        "7. USO:\n",
        "   - Instrucciones de uso\n",
        "   - Ejemplos prácticos\n",
        "   - Capturas de pantalla (descripción)\n",
        "\n",
        "8. ARQUITECTURA:\n",
        "   - Diagrama de componentes\n",
        "   - Flujo de datos\n",
        "   - Integraciones\n",
        "\n",
        "9. API REFERENCE:\n",
        "   - Endpoints principales\n",
        "   - Parámetros\n",
        "   - Respuestas\n",
        "\n",
        "10. PROCESO DE DESARROLLO:\n",
        "    - Metodología utilizada\n",
        "    - Ingeniería de instrucciones aplicada\n",
        "    - Iteraciones del equipo\n",
        "\n",
        "11. CONTRIBUCIÓN:\n",
        "    - Guías para contribuir\n",
        "    - Estándares de código\n",
        "\n",
        "12. LICENCIA:\n",
        "    - Tipo de licencia\n",
        "\n",
        "13. CONTACTO:\n",
        "    - Información del equipo\n",
        "    - Roles y responsabilidades\n",
        "\n",
        "El README debe ser profesional, completo y seguir las mejores prácticas de documentación técnica, incluyendo información sobre el proceso de desarrollo en equipo.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== README.md GENERADO ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Exportar el README.md a archivo\n",
        "readme_content = response.output_text\n",
        "\n",
        "# Guardar el README.md en el directorio actual\n",
        "with open('Stori_Runbook_AI_Assistant_README.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"\\n=== README.md EXPORTADO ===\")\n",
        "print(\"El archivo README.md ha sido guardado en el directorio actual.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paso 3: Conclusiones Finales de la Actividad\n",
        "\n",
        "### Aprendizajes Clave del Equipo\n",
        "\n",
        "1. **Proceso de Ideación y Selección de Proyectos**  \n",
        "   - Se identificó que la diversidad de perspectivas en el equipo permitió descubrir múltiples oportunidades de aplicación de IA.  \n",
        "   - Se realizó una evaluación sistemática de ideas considerando viabilidad técnica, impacto organizacional y recursos disponibles.  \n",
        "   - Se reconoció la importancia de alinear las propuestas con las necesidades reales de la organización.\n",
        "\n",
        "2. **Aplicación de Ingeniería de Instrucciones con LLMs**  \n",
        "   - Se comprobó que el uso de ChatGPT-4 resultó ser una herramienta valiosa para estructurar y desarrollar propuestas de proyecto.  \n",
        "   - Se llevó a cabo una iteración continua con el LLM que permitió refinar y enriquecer la propuesta inicial.  \n",
        "   - Se aprovechó la capacidad del modelo para generar documentación técnica estructurada y profesional.\n",
        "\n",
        "3. **Integración de Técnicas de NLP y LLMs**  \n",
        "   - Se demostró que la combinación de análisis de tópicos (LDA) con generación de contenido mediante LLMs potencia las capacidades del sistema.  \n",
        "   - Se estableció el procesamiento de lenguaje natural como base para sistemas de documentación inteligente.  \n",
        "   - Se enfatizó la importancia de la validación humana en el proceso de generación automática de contenido.\n",
        "\n",
        "### Desafíos Identificados\n",
        "\n",
        "- **Selección de modelo LLM**: Se realizó una evaluación de diferentes opciones considerando costos, capacidades y restricciones organizacionales.  \n",
        "- **Estructuración de prompts**: Se desarrollaron instrucciones efectivas para obtener resultados consistentes y útiles.  \n",
        "- **Integración organizacional**: Se consideraron las áreas y departamentos involucrados en la implementación.  \n",
        "- **Estimación de recursos**: Se evaluó de manera realista los tiempos, costos y tecnologías requeridas.\n",
        "\n",
        "### Propuesta de Proyecto Seleccionada\n",
        "\n",
        "**Stori Runbook AI Assistant**: Sistema de gestión y automatización de documentación operativa utilizando IA.\n",
        "\n",
        "- **Problemática**: Se identificó la gestión ineficiente de runbooks operativos que causa confusión, ineficiencia y falta de estandarización.  \n",
        "- **Solución**: Se propuso una plataforma basada en IA para crear, mantener y consultar runbooks de manera eficiente.  \n",
        "- **Tecnologías**: Se seleccionó ChatGPT-4, procesamiento de lenguaje natural y arquitectura de microservicios.  \n",
        "- **Entregable**: Se generó documentación técnica completa incluyendo README profesional, arquitectura y guías de implementación.\n",
        "\n",
        "### Aplicaciones Futuras Identificadas\n",
        "\n",
        "- Se identificaron sistemas de documentación automática para diferentes tipos de organizaciones.  \n",
        "- Se propusieron asistentes inteligentes para generación y mantenimiento de contenido técnico.  \n",
        "- Se consideraron plataformas de gestión de conocimiento organizacional basadas en IA.  \n",
        "- Se exploraron herramientas de análisis y optimización de procesos operativos.\n",
        "\n",
        "### Reflexiones del Equipo\n",
        "\n",
        "En esta actividad se demostró la importancia de combinar la creatividad humana con las capacidades de los LLMs para desarrollar propuestas de proyecto viables y bien estructuradas. El proceso de ingeniería de instrucciones permitió transformar ideas iniciales en propuestas técnicas completas, estableciendo una base sólida para futuras implementaciones de IA en el contexto organizacional.\n",
        "\n",
        "### Crecimiento Profesional\n",
        "\n",
        "Los miembros del equipo desarrollaron habilidades en:\n",
        "\n",
        "- Evaluación y selección de tecnologías de IA apropiadas para problemas específicos.  \n",
        "- Aplicación efectiva de ingeniería de instrucciones con LLMs.  \n",
        "- Desarrollo de propuestas técnicas estructuradas y profesionales.  \n",
        "- Análisis de viabilidad técnica y organizacional de proyectos de IA.  \n",
        "- Integración de diferentes técnicas de procesamiento de lenguaje natural."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1BtP-Sk0DT-M",
        "6uYgtCvvJSmq",
        "NM0D83j8EWiN",
        "6PKaB_Ge0Shc",
        "i2ywrmsMP_EF",
        "Blrrs1sWwkSx",
        "Kx-dZSFJz9cK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MASTER-AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
