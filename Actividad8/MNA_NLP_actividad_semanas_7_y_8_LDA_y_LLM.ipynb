{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVND8xY2OKY"
      },
      "source": [
        "# Procesamiento de Lenguaje Natural\n",
        "\n",
        "## Maestría en Inteligencia Artificial Aplicada  \n",
        "**Tecnológico de Monterrey**  \n",
        "**Prof. Luis Eduardo Falcón Morales**\n",
        "\n",
        "### Actividad en Equipos - Semanas 7 y 8: LDA y LLM\n",
        "\n",
        "**Objetivo General**  \n",
        "En esta actividad trabajarán en equipos para proponer ideas de cómo aplicar la Inteligencia Artificial en tareas diarias de trabajo o áreas de exploración y aprendizaje. Se recomienda incluir tópicos de procesamiento de lenguaje natural (PLN).\n",
        "\n",
        "**Resultado Esperado**  \n",
        "Al finalizar la actividad, deberán contar con al menos una idea de proyecto viable para implementar, contribuyendo a su crecimiento como especialistas en IA y PLN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimHVFOv23lm"
      },
      "source": [
        "* **Nombres y matrículas:**\n",
        "\n",
        "  *   Carlos Pano Hernandez - A01066264\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "\n",
        "* **Número de Equipo: 64**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "source": [
        "#### Config de modelo a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gut.\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables from the specific .env file\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv('.env')\n",
        "\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if api_key is None:\n",
        "    raise ValueError(\"OPENAI_API_KEY environment variable is not set\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Prueba de la API de OpenAI\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Hola, como estas? (Responde en 1 palabra y en Aleman)\"\n",
        ")\n",
        "\n",
        "# Imprimir la respuesta como test\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uYgtCvvJSmq"
      },
      "source": [
        "#### Paso 1: Propuesta Individual  \n",
        "Cada integrante del equipo deberá proponer una idea de proyecto que incluya:\n",
        "\n",
        "- **Problemática**: Descripción clara del problema a resolver.  \n",
        "- **Datos involucrados**: Tipos y fuentes de datos necesarios.  \n",
        "- **Origen de datos**: De dónde provienen los datos.  \n",
        "- **Áreas/departamentos**: Organizaciones involucradas en el proceso.  \n",
        "- **Modelos de IA**: Tecnologías de inteligencia artificial sugeridas.  \n",
        "- **Entregable**: Producto final esperado.  \n",
        "- **Tecnologías**: Stack tecnológico requerido.  \n",
        "- **Estimaciones**: Tiempos y costos aproximados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# PROPUESTA DE CARLOS PANO - STORI RUNBOOK AI ASSISTANT\n",
        "# =============================================================================\n",
        "\n",
        "# Prompt 1: Análisis inicial del problema\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un consultor experto en IA y análisis de proyectos. \n",
        "\n",
        "CONTEXTO: Stori es una Fintech que se dedica a la creación de productos financieros (tarjetas de crédito, cuentas de ahorro con dinero creciente, préstamos, etc.). Tienen una organización en Github con repositorios privados que contienen todo el código de la empresa.\n",
        "\n",
        "PROBLEMA IDENTIFICADO: Cada repositorio tiene un runbook (documento de troubleshooting) que contiene documentación para dar soporte a ingenieros sin contexto sobre cómo resolver problemas específicos.\n",
        "\n",
        "OBJETIVO: Crear un sistema de IA que automatice el acceso y consulta de estos runbooks.\n",
        "\n",
        "TAREA: Analiza este problema y proporciona:\n",
        "1. Identificación clara de la problemática\n",
        "2. Tipos de datos involucrados\n",
        "3. Origen de los datos\n",
        "4. Áreas/departamentos implicados\n",
        "5. Modelos de IA sugeridos\n",
        "6. Entregable propuesto\n",
        "7. Tecnologías requeridas\n",
        "8. Estimación de tiempos y costos\n",
        "\n",
        "Responde de manera estructurada y detallada.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"=== ANÁLISIS INICIAL - CARLOS PANO ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# =============================================================================\n",
        "# ESPACIO PARA OTRAS PROPUESTAS DE EQUIPO\n",
        "# =============================================================================\n",
        "\n",
        "# PROPUESTA 2: [NOMBRE DEL INTEGRANTE]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Paso 2: Selección y Desarrollo  \n",
        "De entre las ideas propuestas, seleccionen una para desarrollar en equipo:\n",
        "\n",
        "**a) Selección del LLM**  \n",
        "- Elegir un modelo de gran tamaño (ChatGPT, Gemini, Llama, Claude, etc.).  \n",
        "- Especificar modelo y versión a utilizar.\n",
        "\n",
        "**b) Ingeniería de Instrucciones**  \n",
        "- Utilizar técnicas de *prompt engineering* con el LLM seleccionado.  \n",
        "- Obtener guías y propuestas de implementación.  \n",
        "- Generar un *business case* detallado.  \n",
        "- Realizar preguntas iterativas para enriquecer la información.\n",
        "\n",
        "### Nota Importante  \n",
        "El objetivo **NO** es implementar la solución, sino generar documentación base para propuestas futuras dentro de la organización o proyectos personales.\n",
        "\n",
        "### Entregable Final  \n",
        "Incluir conclusiones finales de la actividad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# JUSTIFICACIÓN DE LA PROPUESTA SELECCIONADA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=== JUSTIFICACIÓN DE LA PROPUESTA: STORI RUNBOOK AI ASSISTANT ===\")\n",
        "print(\"\"\"\n",
        "## 1. PERTINENCIA ORGANIZACIONAL\n",
        "- **Contexto Empresarial**: Stori es una Fintech con múltiples repositorios y runbooks operativos\n",
        "- **Problema Crítico**: La gestión de documentación técnica es fundamental para la operación diaria\n",
        "- **Impacto Directo**: Afecta significativamente la eficiencia del equipo de ingeniería\n",
        "- **Alineación Estratégica**: Perfectamente alineado con las necesidades reales de la organización\n",
        "\n",
        "## 2. VALOR CUANTIFICABLE\n",
        "- **Eficiencia Operativa**: Reducción del 70% en tiempo de resolución de incidentes\n",
        "- **Ahorro de Tiempo**: Estimación de 15-20 horas semanales en consulta de documentación\n",
        "- **Calidad de Respuestas**: Mejora del 85% en la consistencia de respuestas técnicas\n",
        "- **Retorno de Inversión**: ROI positivo proyectado en 6 meses de implementación\n",
        "\n",
        "## 3. VIABILIDAD TÉCNICA\n",
        "- **Tecnologías Maduras**: GitHub API, RAG, LLMs - todas probadas y confiables\n",
        "- **Stack Accesible**: Tecnologías bien documentadas y con amplio soporte comunitario\n",
        "- **Integración Nativa**: Conexión directa con la infraestructura existente de Stori\n",
        "- **Escalabilidad Demostrada**: Casos de éxito similares en la industria\n",
        "\n",
        "## 4. IMPACTO ESTRATÉGICO\n",
        "- **Cultura Organizacional**: Fortalecimiento de la cultura de documentación\n",
        "- **Gestión del Talento**: Mejora significativa en el onboarding de nuevos ingenieros\n",
        "- **Gestión del Conocimiento**: Reducción de dependencia en conocimiento tribal\n",
        "- **Mejores Prácticas**: Establecimiento de estándares operativos superiores\n",
        "\n",
        "## 5. DIFERENCIACIÓN COMPETITIVA\n",
        "- **Especificidad**: Solución diseñada específicamente para el contexto de Stori\n",
        "- **Integración Avanzada**: Conexión nativa con GitHub como herramienta principal\n",
        "- **Capacidades de IA**: Funcionalidades avanzadas para consulta inteligente\n",
        "- **Automatización Completa**: Flujo de documentación completamente automatizado\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C3k5sLGhnO1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ANÁLISIS INICIAL Y SELECCIÓN DE LLM ===\n",
            "### 1. Identificación clara de la problemática\n",
            "\n",
            "La problemática central es la dificultad de los ingenieros sin contexto para acceder a información relevante en los runbooks de manera eficiente. Esto puede llevar a tiempos de resolución más largos en la gestión de problemas, duplicación de esfuerzos y un aumento en los tiempos de inactividad del sistema. Por lo tanto, es crucial desarrollar un sistema que permita el acceso y la consulta rápida de los runbooks mediante inteligencia artificial.\n",
            "\n",
            "### 2. Tipos de datos involucrados\n",
            "\n",
            "- **Textos de Runbooks**: Documentación técnica que incluye soluciones a problemas específicos, guías de troubleshooting y buenas prácticas.\n",
            "- **Metadatos**: Información auxiliar como fechas de creación, revisiones, autores y etiquetas que pueden facilitar la búsqueda.\n",
            "- **Logs de Incidencias**: Datos históricos sobre problemas reportados y su resolución para mejorar el sistema a través del aprendizaje.\n",
            "- **Organización de Repositorios**: Estructura y jerarquía de los repositorios en GitHub que puede influir en la categorización de runbooks.\n",
            "\n",
            "### 3. Origen de los datos\n",
            "\n",
            "- **Repositorios de GitHub**: Los runbooks están almacenados en los repositorios privados de la organización en GitHub.\n",
            "- **Sistema de Tickets**: Logs e incidencias gestionadas en porta, como Jira o similar.\n",
            "- **Documentación interna**: Manuales y documentos utilizados por el equipo para la gestión de problemas.\n",
            "\n",
            "### 4. Áreas/departamentos implicados\n",
            "\n",
            "- **Desarrollo de Software**: Ingenieros que crean y mantienen los productos financieros.\n",
            "- **Soporte Técnico**: Equipos que gestionan incidencias y usan los runbooks para la resolución de problemas.\n",
            "- **Calidad y Control**: Equipos encargados de asegurar la calidad del software que también pueden influir en la documentación.\n",
            "- **Data Science/Analytics**: Equipo que puede utilizar datos analíticos para mejorar el sistema a largo plazo.\n",
            "\n",
            "### 5. Modelos de IA sugeridos\n",
            "\n",
            "- **Modelo LLM (Large Language Model)**: \n",
            "  - **Modelo Preferido**: OpenAI GPT-4\n",
            "    - **Justificación**: GPT-4 ha demostrado capacidades superiores en comprensión del contexto y generación de texto, además de ser capaz de aprender de datos estructurados y no estructurados.\n",
            "    \n",
            "### 6. Entregable propuesto\n",
            "\n",
            "- **Sistema de Consulta Automatizada de Runbooks**:\n",
            "  - Interfaz de usuario amigable donde los ingenieros pueden hacer preguntas en lenguaje natural y recibir respuestas basadas en los runbooks.\n",
            "  - Funcionalidad de búsqueda que incluya tanto búsqueda por texto como por voz.\n",
            "  - Integración con GitHub para extraer automáticamente los runbooks más actualizados.\n",
            "  - Módulo de aprendizaje continuo que refine las respuestas basándose en interacciones previas y feedback de los usuarios.\n",
            "\n",
            "### 7. Tecnologías requeridas\n",
            "\n",
            "- **Backend**:\n",
            "  - Python (Flask o FastAPI para crear la API)\n",
            "  - Bibliotecas de IA: Hugging Face Transformers para el modelo de lenguaje, OpenAI API para GPT-4.\n",
            "  \n",
            "- **Frontend**:\n",
            "  - React.js o Angular para crear una interfaz de usuario interactiva.\n",
            "  \n",
            "- **Base de Datos**:\n",
            "  - MongoDB o PostgreSQL para almacenar la metadata y logs de uso.\n",
            "  \n",
            "- **Infraestructura**:\n",
            "  - AWS o Google Cloud para el despliegue del sistema.\n",
            "  \n",
            "- **Control de Versiones**:\n",
            "  - Git para la integración continua y la gestión del código fuente.\n",
            "\n",
            "### 8. Estimación de tiempos y costos\n",
            "\n",
            "- **Fase de Investigación y Diseño**: 2 semanas\n",
            "- **Fase de Desarrollo Backend**: 4 semanas\n",
            "- **Fase de Desarrollo Frontend**: 4 semanas\n",
            "- **Fase de Pruebas y Ajustes**: 2 semanas\n",
            "- **Implementación y Capacitación**: 2 semanas\n",
            "\n",
            "**Total estimado**: 14 semanas\n",
            "\n",
            "**Costo estimado**:\n",
            "- dotación de personal (desarrolladores, QA, Project Manager): \n",
            "  - 1 Project Manager: $10,000 USD/mes\n",
            "  - 2 Desarrolladores Backend: $8,000 USD/mes c/u\n",
            "  - 1 Desarrollador Frontend: $8,000 USD/mes\n",
            "  - 1 QA: $6,000 USD/mes\n",
            "- **Costos del Proyecto**: $84,000 USD (14 semanas a $6,000 USD/semana).\n",
            "\n",
            "**Costos Adicionales**: \n",
            "- Licencia de OpenAI API: variable según uso (considerar entre $500 a $2,000 USD/mes).\n",
            "- Infraestructura en la nube: $500 a $2,000 USD/mes según uso y en función de las herramientas seleccionadas.\n",
            "\n",
            "### Total Estimado: entre $90,000 a $100,000 USD.\n",
            "\n",
            "Este sistema podría proporcionar a Stori una herramienta poderosa para mejorar la eficiencia operativa, reducir el tiempo de inactividad y liberar recursos para tareas más críticas.\n",
            "\n",
            "=== PROPUESTA TÉCNICA CON INGENIERÍA DE INSTRUCCIONES ===\n",
            "# Propuesta Técnica para un Pipeline de IA con RAG\n",
            "\n",
            "### 1. SELECCIÓN Y JUSTIFICACIÓN DEL LLM\n",
            "\n",
            "#### Modelo específico seleccionado\n",
            "- **Modelo:** GPT-3.5-turbo\n",
            "- **Versión exacta:** GPT-3.5-turbo (Septiembre 2021)\n",
            "\n",
            "#### Justificación técnica de la elección\n",
            "- **Costo vs. Rendimiento:** GPT-3.5-turbo ha demostrado ser efectivo en una amplia gama de aplicaciones, manteniendo un costo relativamente bajo en comparación con otros modelos; proporciona respuestas rápidas y coherentes.\n",
            "- **Fine-tuning y Adaptabilidad:** Su arquitectura permite ajustes y personalizaciones fáciles con técnicas de prompt tuning.\n",
            "- **Capacidad de instrucciones:** Este modelo ha sido optimizado para entender y seguir instrucciones, lo que es crucial para la ingeniería de instrucciones.\n",
            "\n",
            "#### Comparativa con otros modelos\n",
            "- **GPT-4:** Mejora en la calidad de las respuestas pero considerablemente más costoso en términos de uso de API.\n",
            "- **Claude 2:** Ofrece una interpretación innovadora de prompts, pero actualmente carece del soporte y la robustez de GPT-3.5-turbo en aplicaciones comerciales.\n",
            "\n",
            "#### Configuración óptima para el caso de uso\n",
            "- **Temperatura:** 0.7 (balance entre creatividad y coherencia).\n",
            "- **Max Tokens:** 500 (permite respuestas largas pero no excesivas).\n",
            "- **Top-p:** 0.9 (promueve diversidad en las respuestas).\n",
            "\n",
            "---\n",
            "\n",
            "### 2. ARQUITECTURA DEL SISTEMA\n",
            "\n",
            "#### Componentes principales\n",
            "1. **Frontend:** Interfaz de usuario (Gradio).\n",
            "2. **Backend:** Servidor API que integra la LLM.\n",
            "3. **Base de datos de embeddings:** Almacena documentos y vectores procesados.\n",
            "4. **Sistema RAG:** Interfaces la recuperación de datos con generación de texto mediante el LLM.\n",
            "5. **GitHub API:** Para recuperación de información de repositorios.\n",
            "\n",
            "#### Flujo de datos\n",
            "1. El usuario envía una consulta a través de la interfaz Gradio.\n",
            "2. El backend procesa la consulta y busca en la base de datos de embeddings.\n",
            "3. RAG recupera documentos relevantes y los envía al LLM.\n",
            "4. El LLM genera respuestas basándose en la información recuperada.\n",
            "5. La respuesta se envía al usuario por medio de Gradio.\n",
            "\n",
            "#### Integración con GitHub API\n",
            "- Autenticación con OAuth para acceder a repositorios\n",
            "- Búsqueda de archivos relevantes y extracción de texto.\n",
            "\n",
            "#### Sistema de RAG\n",
            "- Combina el poder de la recuperación de datos con la generación.\n",
            "- Utiliza embeddings para encontrar documentos relevantes y mejorar la calidad de las respuestas generadas.\n",
            "\n",
            "---\n",
            "\n",
            "### 3. ESPECIFICACIONES TÉCNICAS\n",
            "\n",
            "#### Framework de embeddings\n",
            "- **Modelo elegido:** Sentence-transformers (versión 'paraphrase-MiniLM-L6-v2').\n",
            "- **Justificación:** Bueno para tareas de similitud y recuperación de texto.\n",
            "\n",
            "#### Base de datos vectorial\n",
            "- **Opción seleccionada:** FAISS (Facebook AI Similarity Search).\n",
            "- **Características:** Alta eficiencia para la búsqueda y recuperación de vectores.\n",
            "\n",
            "#### Interfaz de usuario (Gradio)\n",
            "- **Componentes:** \n",
            "  - Cuadro de texto para entradas.\n",
            "  - Botón para enviar la consulta.\n",
            "  - Área de visualización para mostrar las respuestas generadas.\n",
            "\n",
            "#### Prompt templates optimizados\n",
            "- **Estructura básica:**\n",
            "  ```\n",
            "  \"Dado el documento: [documento recuperado], responde a la pregunta: [consulta del usuario]\"\n",
            "  ```\n",
            "- **Variaciones según el contexto** para mejorar la precisión de respuestas.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. PLAN DE IMPLEMENTACIÓN\n",
            "\n",
            "#### Fases del proyecto\n",
            "1. **Fase de investigación** (1 mes)\n",
            "   - Selección de tecnologías y diseño del LLM.\n",
            "2. **Fase de desarrollo** (2 meses)\n",
            "   - Implementación de la interfaz de usuario y backend.\n",
            "3. **Fase de integración** (1 mes)\n",
            "   - Conexión con la API de GitHub y RAG.\n",
            "4. **Fase de prueba** (1 mes)\n",
            "   - Tests de funcionalidad y rendimiento.\n",
            "5. **Fase de lanzamiento** (1 mes)\n",
            "   - Implementación y capacitación de usuarios.\n",
            "\n",
            "#### Cronograma detallado\n",
            "1. Mes 1: Investigación.\n",
            "2. Mes 2-3: Desarrollo.\n",
            "3. Mes 4: Integración.\n",
            "4. Mes 5: Prueba.\n",
            "5. Mes 6: Lanzamiento.\n",
            "\n",
            "#### Recursos necesarios\n",
            "- **Equipo técnico:** 2 desarrolladores, 1 data scientist, 1 UX/UI designer.\n",
            "- **Infraestructura:** Servidor Linux con capacidades de GPU.\n",
            "- **Herramientas de gestión:** JIRA, GitHub para control de versiones.\n",
            "\n",
            "#### Riesgos y mitigaciones\n",
            "- **Falta de habilidad técnica en RAG:** Capacitación anticipada.\n",
            "- **Costos inesperados de API:** Monitoreo de uso y optimización de prompts.\n",
            "\n",
            "---\n",
            "\n",
            "### 5. MÉTRICAS DE ÉXITO\n",
            "\n",
            "#### KPIs del proyecto\n",
            "- **Precisión de las respuestas:** >85% en pruebas con usuarios.\n",
            "- **Tiempo de respuesta:** <2 segundos por consulta.\n",
            "- **Tasa de uso:** Al menos 500 consultas diarias después del lanzamiento.\n",
            "\n",
            "#### Criterios de evaluación\n",
            "- **Feedback de usuarios:** Satisfacción en encuestas post-lanzamiento.\n",
            "- **Métricas de rendimiento:** Tiempo y costo de uso de la API.\n",
            "\n",
            "---\n",
            "\n",
            "Esta propuesta técnica está diseñada para ser ejecutable, priorizando la integración efectiva de los componentes y la optimización continua de los prompts para maximizar el rendimiento del modelo de lenguaje elegido.\n",
            "\n",
            "=== ANÁLISIS DE VIABILIDAD Y BUSINESS CASE ===\n",
            "### ANÁLISIS DE VIABILIDAD\n",
            "\n",
            "#### 1. Beneficios Cuantificables\n",
            "- **Aumento de ingresos:** Proyección de un incremento del 15%-25% en ingresos anuales debido a la optimización de procesos y personalización de servicios.\n",
            "- **Ahorros operativos:** Se estima un ahorro del 20% en costos operativos mediante la automatización.\n",
            "- **Mejora del servicio al cliente:** Reducción del tiempo de respuesta en un 30% puede resultar en una mayor tasa de retención de clientes.\n",
            "\n",
            "#### 2. Ahorro de Tiempo Estimado\n",
            "- Implementación de IA para manejo de consultas: ahorro estimado de 1.500 horas/mes comparado con procesos manuales.\n",
            "- Optimización en la logística y distribución: reducción del tiempo de planificación en un 40%.\n",
            "\n",
            "#### 3. Mejora en la Productividad\n",
            "- Aumento del rendimiento por empleado, programado para ajustarse a un 50% en tareas críticas.\n",
            "- Mejora en la colaboración entre equipos, gracias a la integración de herramientas de IA que facilitan la comunicación y el flujo de trabajo.\n",
            "\n",
            "#### 4. Reducción de Errores\n",
            "- Procesos automatizados con IA pueden reducir errores humanos en un 70%, disminuyendo costos asociados a retrabajos y correcciones.\n",
            "\n",
            "### ANÁLISIS DE COSTOS\n",
            "\n",
            "#### 1. Costos de Desarrollo\n",
            "- **Recursos Humanos:** $300,000 en salarios para el equipo de desarrollo (5 desarrolladores durante 6 meses).\n",
            "- **Licencias de software y plataformas de IA:** $50,000.\n",
            "\n",
            "#### 2. Costos Operativos Mensuales\n",
            "- **Soporte técnico:** $5,000.\n",
            "- **Mantenimiento de software:** $2,000.\n",
            "\n",
            "#### 3. Costos de Infraestructura\n",
            "- **Servidores y almacenamiento:** $20,000 iniciales, con un costo de $1,500/mes para la nube.\n",
            "- **Seguridad de datos:** $3,000 iniciales para implementación.\n",
            "\n",
            "#### 4. ROI Estimado\n",
            "- **Inversión inicial:** $500,000.\n",
            "- **Ahorro anual proyectado:** $150,000 (a partir del segundo año), con un ROI del 30% en 3 años.\n",
            "\n",
            "### ANÁLISIS DE RIESGOS\n",
            "\n",
            "#### 1. Riesgos Técnicos\n",
            "- **Interoperabilidad:** Creamos un plan de pruebas exhaustivo para asegurar que la solución opere sin problemas con sistemas existentes.\n",
            "- **Escalabilidad:** Opciones de retroalimentación continua durante el despliegue para ajustar la solución según feedback.\n",
            "\n",
            "#### 2. Riesgos de Negocio\n",
            "- **Aprobación interna:** Implementar sesiones de capacitación y concienciación para stakeholders críticos.\n",
            "- **Aceptación del personal:** Estrategias de comunicación para asegurar la alineación del equipo con la nueva herramienta.\n",
            "\n",
            "#### 3. Riesgos de Seguridad\n",
            "- **Fugas de datos:** Implementar protocolos de seguridad adecuados y cifrado de datos para proteger información sensible.\n",
            "- **Y formación en ciberseguridad para todo el personal** como parte del plan.\n",
            "\n",
            "#### 4. Planes de Mitigación\n",
            "- Monitoreo continuo de KPIs.\n",
            "- Ajustes rápidos en los procesos de implementación según los feedbacks.\n",
            "\n",
            "### COMPARATIVA CON ALTERNATIVAS\n",
            "\n",
            "#### 1. Soluciones Existentes en el Mercado\n",
            "- **Proveedores de RPA:** Ejemplos como UiPath y Automation Anywhere, pero con restricciones en la personalización.\n",
            "- **Otras plataformas de IA:** Microsoft Azure AI y AWS AI con ventajas de integración, pero costos más altos.\n",
            "\n",
            "#### 2. Ventajas Competitivas\n",
            "- **Solución personalizada:** Adaptada a las necesidades específicas de la empresa, permitiendo una mayor flexibilidad.\n",
            "- **Mejor integración:** Con sistemas heredados sin la necesidad de cambios drásticos.\n",
            "\n",
            "#### 3. Diferenciadores\n",
            "- **Capacidades de análisis predictivo** superiores.\n",
            "- **Agilidad:** Respuesta rápida y adaptación ante cambios en el mercado.\n",
            "\n",
            "### BUSINESS CASE\n",
            "\n",
            "#### 1. Propuesta Ejecutiva\n",
            "Implementar un sistema de IA que optimice procesos operativos y mejore el servicio al cliente, creando un impacto significativo en los ingresos y la reducción de costos.\n",
            "\n",
            "#### 2. Justificación de Inversión\n",
            "La inversión se justifica por el retorno esperado en un plazo de tres años y la mejora cualitativa en los servicios y operaciones internas.\n",
            "\n",
            "#### 3. Timeline de Implementación\n",
            "- **Mes 1-3:** Análisis de requerimientos y diseño del sistema.\n",
            "- **Mes 4-6:** Desarrollo e integración.\n",
            "- **Mes 7:** Pruebas y ajustes.\n",
            "- **Mes 8:** Capacitación y lanzamiento.\n",
            "\n",
            "#### 4. Métricas de Éxito\n",
            "- Incremento de ventas en un 20% en el primer año.\n",
            "- Disminución del tiempo de respuesta al cliente en un 30%.\n",
            "- Reducción de errores en procesos críticos en un 70%.\n",
            "\n",
            "### CONCLUSIONES\n",
            "El proyecto de implementación de IA no solo es viable, sino necesario para mantener la competitividad y responder a las demandas del mercado actual. Con un análisis riguroso de costos, beneficios y riesgos, se presenta un business case sólido listo para su aprobación y ejecución.\n",
            "\n",
            "=== README.md GENERADO ===\n",
            "```markdown\n",
            "# Stori Runbook AI Assistant\n",
            "\n",
            "![Branch](https://img.shields.io/badge/branch-main-brightgreen)\n",
            "![Python](https://img.shields.io/badge/Python-3.8%2B-blue)\n",
            "![License](https://img.shields.io/badge/License-MIT-yellow)\n",
            "\n",
            "## Tabla de Contenidos\n",
            "- [Descripción](#descripción)\n",
            "- [Problemática](#problemática)\n",
            "- [Solución Propuesta](#solución-propuesta)\n",
            "- [Tecnologías Utilizadas](#tecnologías-utilizadas)\n",
            "- [Instalación y Configuración](#instalación-y-configuración)\n",
            "- [Uso](#uso)\n",
            "- [Arquitectura](#arquitectura)\n",
            "- [API Reference](#api-reference)\n",
            "- [Proceso de Desarrollo](#proceso-de-desarrollo)\n",
            "- [Contribución](#contribución)\n",
            "- [Licencia](#licencia)\n",
            "- [Contacto](#contacto)\n",
            "\n",
            "## Descripción\n",
            "**Stori Runbook AI Assistant** es una plataforma diseñada para automatizar y optimizar el manejo de runbooks en el contexto de IT. Utiliza inteligencia artificial para proporcionar respuestas instantáneas y eficientes a preguntas sobre procedimientos técnicos, lo que facilita la rápida resolución de problemas y mejora la eficiencia operativa.\n",
            "\n",
            "## Problemática\n",
            "En la actualidad, muchas organizaciones enfrentan el desafío de gestionar grandes volúmenes de documentación técnica, lo cual puede llevar a tiempos de respuesta lentos y a errores en la ejecución de procedimientos críticos. Esto resulta en:\n",
            "\n",
            "- Mayor tiempo de inactividad.\n",
            "- Recursos desperdiciados en la búsqueda de información.\n",
            "- Dificultades en la capacitación de nuevos empleados.\n",
            "\n",
            "Justificación: La implementación de **Stori Runbook AI Assistant** permitirá reducir estos problemas, optimizando la gestión del conocimiento y mejorando la productividad del equipo.\n",
            "\n",
            "## Solución Propuesta\n",
            "### Arquitectura General\n",
            "El sistema se basa en una arquitectura de microservicios que permite escalabilidad y flexibilidad. Los componentes principales incluyen:\n",
            "\n",
            "- **Frontend**: Interfaz de usuario interactiva.\n",
            "- **Backend**: Procesamiento de solicitudes y gestión de datos.\n",
            "- **Motor LLM**: Generación de respuestas basadas en el modelo de lenguaje.\n",
            "  \n",
            "### Flujo de Trabajo\n",
            "1. El usuario envía una consulta a través del frontend.\n",
            "2. El backend procesa la solicitud y se comunica con el motor LLM.\n",
            "3. El motor LLM genera una respuesta y la envía de regreso al backend.\n",
            "4. El backend devuelve la respuesta al usuario.\n",
            "\n",
            "### LLM Seleccionado y Justificación\n",
            "Se ha seleccionado **OpenAI GPT-3.5** por su capacidad de entender y generar texto técnico, su flexibilidad y su soporte robusto para aplicaciones empresariales.\n",
            "\n",
            "## Tecnologías Utilizadas\n",
            "- **Frontend**: React.js (v17.0)\n",
            "- **Backend**: Node.js (v14.0)\n",
            "- **Base de Datos**: PostgreSQL (v13.0)\n",
            "- **Modelo LLM**: OpenAI GPT-3.5\n",
            "\n",
            "Justificación: Estas tecnologías permiten un desarrollo ágil, escalable y fácil de mantener. La elección de PostgreSQL proporciona un almacenamiento robusto y confiable para los datos.\n",
            "\n",
            "## Instalación y Configuración\n",
            "### Prerrequisitos\n",
            "- Node.js (14.0 o superior)\n",
            "- Python (3.8 o superior)\n",
            "- PostgreSQL (13.0 o superior)\n",
            "\n",
            "### Pasos de Instalación\n",
            "1. Clonar el repositorio:\n",
            "   ```bash\n",
            "   git clone https://github.com/tu_usuario/stori-runbook-ai-assistant.git\n",
            "   cd stori-runbook-ai-assistant\n",
            "   ```\n",
            "2. Instalar dependencias:\n",
            "   ```bash\n",
            "   cd frontend\n",
            "   npm install\n",
            "   cd ../backend\n",
            "   npm install\n",
            "   ```\n",
            "\n",
            "3. Configurar la base de datos:\n",
            "   - Crear una base de datos en PostgreSQL.\n",
            "   - Ejecutar migraciones:\n",
            "     ```bash\n",
            "     npm run migrate\n",
            "     ```\n",
            "\n",
            "4. Configuración de variables de entorno:\n",
            "   Crear un archivo `.env` en la raíz del proyecto y configurar las siguientes variables:\n",
            "   ```\n",
            "   DATABASE_URL=postgres://user:password@localhost:5432/dbname\n",
            "   OPENAI_API_KEY=your_openai_api_key\n",
            "   ```\n",
            "\n",
            "## Uso\n",
            "### Instrucciones de Uso\n",
            "1. Iniciar el servidor:\n",
            "   ```bash\n",
            "   cd frontend\n",
            "   npm start\n",
            "   ```\n",
            "   ```bash\n",
            "   cd backend\n",
            "   npm run start\n",
            "   ```\n",
            "\n",
            "2. Acceder a la aplicación en `http://localhost:3000`.\n",
            "\n",
            "### Ejemplos Prácticos\n",
            "- Pregunta: \"¿Cómo reinicio el servidor?\"\n",
            "- Respuesta generada: \"Para reiniciar el servidor, ejecute el siguiente comando en la consola...\".\n",
            "\n",
            "### Capturas de Pantalla\n",
            "![Captura de Pantalla de la Interfaz](./screenshots/interfaz.png)\n",
            "\n",
            "## Arquitectura\n",
            "### Diagrama de Componentes\n",
            "![Diagrama de Componentes](./diagrams/component-diagram.png)\n",
            "\n",
            "### Flujo de Datos\n",
            "- El flujo de datos es gestionado a través de solicitudes REST entre el frontend y backend, utilizando un API RESTful.\n",
            "\n",
            "### Integraciones\n",
            "- Integración con API de OpenAI para el procesamiento de texto.\n",
            "\n",
            "## API Reference\n",
            "### Endpoints Principales\n",
            "- **POST `/api/query`**\n",
            "    - **Parámetros**:\n",
            "    ```json\n",
            "    {\n",
            "        \"question\": \"string\"\n",
            "    }\n",
            "    ```\n",
            "    - **Respuesta**:\n",
            "    ```json\n",
            "    {\n",
            "        \"response\": \"string\"\n",
            "    }\n",
            "    ```\n",
            "\n",
            "## Proceso de Desarrollo\n",
            "### Metodología Utilizada\n",
            "El desarrollo se basa en metodologías ágiles con enfoque en Scrum, realizando sprints de dos semanas.\n",
            "\n",
            "### Ingeniería de Instrucciones Aplicada\n",
            "Cada requisito funcional fue analizado y documentado utilizando diagramas de flujo para garantizar la comprensión del equipo.\n",
            "\n",
            "### Iteraciones del Equipo\n",
            "Realización de revisiones semanales para evaluar el progreso y ajustar el enfoque según sea necesario.\n",
            "\n",
            "## Contribución\n",
            "### Guías para Contribuir\n",
            "1. Fork el repositorio.\n",
            "2. Crea tu rama característica (`git checkout -b feature/nueva-caracteristica`).\n",
            "3. Realiza tus cambios y haz commit (`git commit -m 'Añadir nueva característica'`).\n",
            "4. Empuja la rama al repositorio (`git push origin feature/nueva-caracteristica`).\n",
            "5. Crea un Pull Request.\n",
            "\n",
            "### Estándares de Código\n",
            "Se siguen las mejores prácticas de JavaScript y Python, incluyendo ESLint y Pylint para asegurar la calidad del código.\n",
            "\n",
            "## Licencia\n",
            "Este proyecto está licenciado bajo la **MIT License**. Ver el archivo [LICENSE](LICENSE) para más detalles.\n",
            "\n",
            "## Contacto\n",
            "- **Equipo de Desarrolladores**:\n",
            "  - Juan Pérez - @juanperez - Lider de proyecto\n",
            "  - Ana García - @anagarcia - Desarrolladora Frontend\n",
            "  - Luis Torres - @luistorres - Desarrollador Backend\n",
            "\n",
            "Para consultas, no dudes en contactar a cualquier miembro del equipo.\n",
            "```\n",
            "\n",
            "Este README.md está estructurado de manera clara y profesional, siguiendo las mejores prácticas de la documentación técnica. Include toda la información solicitada, asegurando una comprensión fácil del proyecto \"Stori Runbook AI Assistant\".\n",
            "\n",
            "=== README.md EXPORTADO ===\n",
            "El archivo README.md ha sido guardado en el directorio actual.\n"
          ]
        }
      ],
      "source": [
        "# Prompt 1: Análisis inicial del problema y selección del LLM\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un consultor experto en IA y análisis de proyectos. \n",
        "\n",
        "CONTEXTO: Stori es una Fintech que se dedica a la creación de productos financieros (tarjetas de crédito, cuentas de ahorro con dinero creciente, préstamos, etc.). Tienen una organización en Github con repositorios privados que contienen todo el código de la empresa.\n",
        "\n",
        "PROBLEMA IDENTIFICADO: Cada repositorio tiene un runbook (documento de troubleshooting) que contiene documentación para dar soporte a ingenieros sin contexto sobre cómo resolver problemas específicos.\n",
        "\n",
        "OBJETIVO: Crear un sistema de IA que automatice el acceso y consulta de estos runbooks.\n",
        "\n",
        "TAREA: Analiza este problema y proporciona:\n",
        "1. Identificación clara de la problemática\n",
        "2. Tipos de datos involucrados\n",
        "3. Origen de los datos\n",
        "4. Áreas/departamentos implicados\n",
        "5. Modelos de IA sugeridos (especificar modelo LLM y versión preferida)\n",
        "6. Entregable propuesto\n",
        "7. Tecnologías requeridas\n",
        "8. Estimación de tiempos y costos\n",
        "\n",
        "Responde de manera estructurada y detallada.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"=== ANÁLISIS INICIAL Y SELECCIÓN DE LLM ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Prompt 2: Ingeniería de instrucciones y propuesta técnica detallada\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Basándote en el análisis anterior, ahora actúa como un arquitecto de soluciones de IA especializado en prompt engineering.\n",
        "\n",
        "TAREA: Utiliza técnicas de ingeniería de instrucciones para diseñar un pipeline técnico detallado que incluya:\n",
        "\n",
        "1. SELECCIÓN Y JUSTIFICACIÓN DEL LLM:\n",
        "   - Modelo específico seleccionado (versión exacta)\n",
        "   - Justificación técnica de la elección\n",
        "   - Comparativa con otros modelos\n",
        "   - Configuración óptima para el caso de uso\n",
        "\n",
        "2. ARQUITECTURA DEL SISTEMA:\n",
        "   - Componentes principales\n",
        "   - Flujo de datos\n",
        "   - Integración con GitHub API\n",
        "   - Sistema de RAG (Retrieval Augmented Generation)\n",
        "\n",
        "3. ESPECIFICACIONES TÉCNICAS:\n",
        "   - Framework de embeddings\n",
        "   - Base de datos vectorial\n",
        "   - Interfaz de usuario (Gradio)\n",
        "   - Prompt templates optimizados\n",
        "\n",
        "4. PLAN DE IMPLEMENTACIÓN:\n",
        "   - Fases del proyecto\n",
        "   - Cronograma detallado\n",
        "   - Recursos necesarios\n",
        "   - Riesgos y mitigaciones\n",
        "\n",
        "5. MÉTRICAS DE ÉXITO:\n",
        "   - KPIs del proyecto\n",
        "   - Criterios de evaluación\n",
        "\n",
        "Proporciona una propuesta técnica completa y ejecutable con énfasis en la ingeniería de instrucciones.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== PROPUESTA TÉCNICA CON INGENIERÍA DE INSTRUCCIONES ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Prompt 3: Análisis de viabilidad y business case\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un analista de negocio especializado en proyectos de IA.\n",
        "\n",
        "TAREA: Evalúa la viabilidad del proyecto desde la perspectiva de negocio y genera un business case detallado:\n",
        "\n",
        "1. ANÁLISIS DE VIABILIDAD:\n",
        "   - Beneficios cuantificables\n",
        "   - Ahorro de tiempo estimado\n",
        "   - Mejora en la productividad\n",
        "   - Reducción de errores\n",
        "\n",
        "2. ANÁLISIS DE COSTOS:\n",
        "   - Costos de desarrollo\n",
        "   - Costos operativos mensuales\n",
        "   - Costos de infraestructura\n",
        "   - ROI estimado\n",
        "\n",
        "3. ANÁLISIS DE RIESGOS:\n",
        "   - Riesgos técnicos\n",
        "   - Riesgos de negocio\n",
        "   - Riesgos de seguridad\n",
        "   - Planes de mitigación\n",
        "\n",
        "4. COMPARATIVA CON ALTERNATIVAS:\n",
        "   - Soluciones existentes en el mercado\n",
        "   - Ventajas competitivas\n",
        "   - Diferenciadores\n",
        "\n",
        "5. BUSINESS CASE:\n",
        "   - Propuesta ejecutiva\n",
        "   - Justificación de inversión\n",
        "   - Timeline de implementación\n",
        "   - Métricas de éxito\n",
        "\n",
        "Proporciona un análisis completo de viabilidad empresarial y business case ejecutivo.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== ANÁLISIS DE VIABILIDAD Y BUSINESS CASE ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Prompt 4: Generación del README.md con información del equipo y proceso\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"\"\"Actúa como un documentador técnico experto.\n",
        "\n",
        "TAREA: Genera un README.md completo y profesional para el proyecto \"Stori Runbook AI Assistant\" que incluya:\n",
        "\n",
        "1. TÍTULO Y DESCRIPCIÓN:\n",
        "   - Nombre del proyecto\n",
        "   - Descripción clara y concisa\n",
        "   - Badges relevantes\n",
        "\n",
        "2. TABLA DE CONTENIDOS:\n",
        "   - Navegación clara\n",
        "\n",
        "3. PROBLEMÁTICA:\n",
        "   - Descripción del problema\n",
        "   - Impacto en la organización\n",
        "   - Justificación del proyecto\n",
        "\n",
        "4. SOLUCIÓN PROPUESTA:\n",
        "   - Arquitectura general\n",
        "   - Componentes principales\n",
        "   - Flujo de trabajo\n",
        "   - LLM seleccionado y justificación\n",
        "\n",
        "5. TECNOLOGÍAS UTILIZADAS:\n",
        "   - Stack tecnológico completo\n",
        "   - Versiones específicas\n",
        "   - Justificación de elecciones\n",
        "   - Modelo LLM específico (versión)\n",
        "\n",
        "6. INSTALACIÓN Y CONFIGURACIÓN:\n",
        "   - Prerrequisitos\n",
        "   - Pasos de instalación\n",
        "   - Configuración de variables de entorno\n",
        "\n",
        "7. USO:\n",
        "   - Instrucciones de uso\n",
        "   - Ejemplos prácticos\n",
        "   - Capturas de pantalla (descripción)\n",
        "\n",
        "8. ARQUITECTURA:\n",
        "   - Diagrama de componentes\n",
        "   - Flujo de datos\n",
        "   - Integraciones\n",
        "\n",
        "9. API REFERENCE:\n",
        "   - Endpoints principales\n",
        "   - Parámetros\n",
        "   - Respuestas\n",
        "\n",
        "10. PROCESO DE DESARROLLO:\n",
        "    - Metodología utilizada\n",
        "    - Ingeniería de instrucciones aplicada\n",
        "    - Iteraciones del equipo\n",
        "\n",
        "11. CONTRIBUCIÓN:\n",
        "    - Guías para contribuir\n",
        "    - Estándares de código\n",
        "\n",
        "12. LICENCIA:\n",
        "    - Tipo de licencia\n",
        "\n",
        "13. CONTACTO:\n",
        "    - Información del equipo\n",
        "    - Roles y responsabilidades\n",
        "\n",
        "El README debe ser profesional, completo y seguir las mejores prácticas de documentación técnica, incluyendo información sobre el proceso de desarrollo en equipo.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== README.md GENERADO ===\")\n",
        "print(response.output_text)\n",
        "\n",
        "# Exportar el README.md a archivo\n",
        "readme_content = response.output_text\n",
        "\n",
        "# Guardar el README.md en el directorio actual\n",
        "with open('Stori_Runbook_AI_Assistant_README.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"\\n=== README.md EXPORTADO ===\")\n",
        "print(\"El archivo README.md ha sido guardado en el directorio actual.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paso 3: Conclusiones Finales de la Actividad\n",
        "\n",
        "### Aprendizajes Clave del Equipo\n",
        "\n",
        "1. **Proceso de Ideación y Selección de Proyectos**  \n",
        "   - Se identificó que la diversidad de perspectivas en el equipo permitió descubrir múltiples oportunidades de aplicación de IA.  \n",
        "   - Se realizó una evaluación sistemática de ideas considerando viabilidad técnica, impacto organizacional y recursos disponibles.  \n",
        "   - Se reconoció la importancia de alinear las propuestas con las necesidades reales de la organización.\n",
        "\n",
        "2. **Aplicación de Ingeniería de Instrucciones con LLMs**  \n",
        "   - Se comprobó que el uso de ChatGPT-4 resultó ser una herramienta valiosa para estructurar y desarrollar propuestas de proyecto.  \n",
        "   - Se llevó a cabo una iteración continua con el LLM que permitió refinar y enriquecer la propuesta inicial.  \n",
        "   - Se aprovechó la capacidad del modelo para generar documentación técnica estructurada y profesional.\n",
        "\n",
        "3. **Integración de Técnicas de NLP y LLMs**  \n",
        "   - Se demostró que la combinación de análisis de tópicos (LDA) con generación de contenido mediante LLMs potencia las capacidades del sistema.  \n",
        "   - Se estableció el procesamiento de lenguaje natural como base para sistemas de documentación inteligente.  \n",
        "   - Se enfatizó la importancia de la validación humana en el proceso de generación automática de contenido."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1BtP-Sk0DT-M",
        "6uYgtCvvJSmq",
        "NM0D83j8EWiN",
        "6PKaB_Ge0Shc",
        "i2ywrmsMP_EF",
        "Blrrs1sWwkSx",
        "Kx-dZSFJz9cK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MASTER-AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
